# -*- coding: utf-8 -*-
"""CMPE 492.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_NyD2sntPLPA7g0-ltrEI1Jjj61rC5ve

# **Machine Learning for Protein Similarity Computation**
"""

import io
import json
import random
import re
import sys

# import lightgbm
import numpy as np
import pandas as pd
from transformers import AutoModel, AutoTokenizer

import logging

SW_SCORES_PATH = "sw_sim_matrix.csv"

PROTBERT 


print("Getting ProtBert Model and Tokenizer")
PROTEIN_TOKENIZER = AutoTokenizer.from_pretrained('Rostlab/prot_bert', do_lower_case=False)
PROTBERT = AutoModel.from_pretrained('Rostlab/prot_bert')
PROTEIN_TOKENIZER.save_pretrained("/Users/hazelcast/Desktop/protein-similarity-computation-model/")
PROTBERT.save_pretrained("/Users/hazelcast/Desktop/protein-similarity-computation-model/")
print("Model and tokenizer saved in local")

def get_protein_sequences_json(file_path):
  '''
  
  Returns:
    Proteins object storing <str, str>:
      - Key: name
      - Value: sequence
  '''
  p_file = open(file_path)
  proteins = json.load(p_file)

  logging.info("Reading protein sequences COMPLETE.")
  for name, sequence in proteins.items():
    logging.debug(f'Name:{name}')
    logging.debug(f'Sequence:{sequence}')

  return proteins


def get_similarity_matrix(filename):
  df =  pd.read_csv(filename)
  logging.info('Similarity matrix is obtained.')

  return df


def get_protbert_embedding(aa_sequence: str):
  cleaned_sequence = re.sub(r'[UZOB]', 'X', aa_sequence)
  tokens = PROTEIN_TOKENIZER(cleaned_sequence, return_tensors='pt')
  output = PROTBERT(**tokens)
  return output.last_hidden_state.detach().numpy().mean(axis=1)


def prepare_similarity_scores(similarity_matrix):
  similarity_score_dict = {}

  for _, score_list in similarity_matrix.iterrows():
    c = 0
    for score in score_list[1:]:
      c += 1
      similarity_score_dict[(score_list[0], similarity_matrix.columns[c])] = score

    return similarity_score_dict


def prepare_model_data(similarity_matrix: pd.DataFrame):
  plain_data = list(prepare_similarity_scores(similarity_matrix).items())
  random.shuffle(plain_data)

  train_data = plain_data[0:400]
  test_data = plain_data[400:]

  return train_data, test_data

def update_protein_seq(file_path):
    p_file = open(file_path)
    proteins = json.load(p_file)

    proteins_with_space = {}
    for name, sequence in proteins.items():
        proteins_with_space[name] = sequence.replace("", " ")[1: -1]
    
    return proteins_with_space
        
def dict_dump(dictionary, name):
    '''
    -> Outputs the dictionary to a json file
    '''
    fout = open(f"{name}.json","w",encoding="utf-8")
    json.dump(dictionary, fout)
    fout.flush()
    fout.close()

def main():
    print("aaa")

if __name__ == "__main__":
    main()

"""
similarity_matrix = get_similarity_matrix('sw_sim_matrix.csv')
protein_sequences = get_protein_sequences_json('proteins.json')

train_data, test_data = prepare_model_data(similarity_matrix)

x = get_protbert_embedding("MDRMKKIKRQLSMTLRGGRGIDKTNGAPEQIGLDESGGGGGSDPGEAPTRAAPGELRSARGPLSSAPEIVHEDLKMGSDGESDQASATSSDEVQSPVRVRMRNHPPRKISTEDINKRLSLPADIRLPEGYLEKLTLNSPIFDKPLSRRLRRVSLSEIGFGKLETYIKLDKLGEGTYATVYKGKSKLTDNLVALKEIRLEHEEGAPCTAIREVSLLKDLKHANIVTLHDIIHTEKSLTLVFEYLDKDLKQYLDDCGNIINMHNVKLFLFQLLRGLAYCHRQKVLHRDLKPQNLLINERGELKLADFGLARAKSIPTKTYSNEVVTLWYRPPDILLGSTDYSTQIDMWGVGCIFYEMATGRPLFPGSTVEEQLHFIFRILGTPTEETWPGILSNEEFKTYNYPKYRAEALLSHAPRLDSDGADLLTKLLQFEGRNRISAEDAMKHPFFLSLGERIHKLPDTTSIFALKEIQLQKEASLRSSSMPDSGRPAFRVVDTEF")
print()

print(train_X["P53350"])
asd = np.concatenate((train_X["P53350"],np.flip(train_X["P53350"])), axis=1)
print(asd)
print(np.flip(asd))
print(np.shape(asd))

train_X_final = {}
train_Y_final = {}
for id, vector in train_X.items():
  for id2, vector2 in train_X.items():
    train_X_final[(id, id2)] = np.concatenate((vector, vector2), axis=1)
    train_Y_final[(id, id2)] = SW_score_dict[(id, id2)]


_prot = get_protbert_embedding("MDRMKKIKRQLSMTLRGGRGIDKTNGAPEQIGLDESGGGGGSDPGEAPTRAAPGELRSARGPLSSAPEIVHEDLKMGSDGESDQASATSSDEVQSPVRVRMRNHPPRKISTEDINKRLSLPADIRLPEGYLEKLTLNSPIFDKPLSRRLRRVSLSEIGFGKLETYIKLDKLGEGTYATVYKGKSKLTDNLVALKEIRLEHEEGAPCTAIREVSLLKDLKHANIVTLHDIIHTEKSLTLVFEYLDKDLKQYLDDCGNIINMHNVKLFLFQLLRGLAYCHRQKVLHRDLKPQNLLINERGELKLADFGLARAKSIPTKTYSNEVVTLWYRPPDILLGSTDYSTQIDMWGVGCIFYEMATGRPLFPGSTVEEQLHFIFRILGTPTEETWPGILSNEEFKTYNYPKYRAEALLSHAPRLDSDGADLLTKLLQFEGRNRISAEDAMKHPFFLSLGERIHKLPDTTSIFALKEIQLQKEASLRSSSMPDSGRPAFRVVDTEF")
print(_prot)

!pip install biopython

aligner = Align.PairwiseAligner()
aligner.mode = "local"
print(aligner.algorithm)
p1 = "MSKSKCSVGLMSSVVAPAKEPNAVGPKEVELILVKEQNGVQLTSSTLTNPRQSPVEAQDRETWGKKIDFLLSVIGFAVDLANVWRFPYLCYKNGGGAFLVPYLLFMVIAGMPLFYMELALGQFNREGAAGVWKICPILKGVGFTVILISLYVGFFYNVIIAWALHYLFSSFTTELPWIHCNNSWNSPNCSDAHPGDSSGDSSGLNDTFGTTPAAEYFERGVLHLHQSHGIDDLGPPRWQLTACLVLVIVLLYFSLWKGVKTSGKVVWITATMPYVVLTALLLRGVTLPGAIDGIRAYLSVDFYRLCEASVWIDAATQVCFSLGVGFGVLIAFSSYNKFTNNCYRDAIVTTSINSLTSFSSGFVVFSFLGYMAQKHSVPIGDVAKDGPGLIFIIYPEAIATLPLSSAWAVVFFIMLLTLGIDSAMGGMESVITGLIDEFQLLHRHRELFTLFIVLATFLLSLFCVTNGGIYVFTLLDHFAAGTSILFGVLIEAIGVAWFYGVGQFSDDIQQMTGQRPSLYWRLCWKLVSPCFLLFVVVVSIVTFRPPHYGAYIFPDWANALGWVIATSSMAMVPIYAAYKFCSLPGSFREKLAYAIAPEKDRELVDRGEVRQFTLRHWLKV"
p2 = "MNRYTTIRQLGDGTYGSVLLGRSIESGELIAIKKMKRKFYSWEECMNLREVKSLKKLNHANVVKLKEVIRENDHLYFIFEYMKENLYQLIKERNKLFPESAIRNIMYQILQGLAFIHKHGFFHRDLKPENLLCMGPELVKIADFGLAREIRSKPPYTDYVSTRWYRAPEVLLRSTNYSSPIDVWAVGCIMAEVYTLRPLFPGASEIDTIFKICQVLGTPKKTDWPEGYQLSSAMNFRWPQCVPNNLKTLIPNASSEAVQLLRDMLQWDPKKRPTASQALRYPYFQVGHPLGSTTQNLQDSEKPQKGILEKAGPPPYIKPVPPAQPPAKPHTRISSRQHQASQPPLHLTYPYKAEVSRTDHPSHLQEDKPSPLLFPSLHNKHPQSKITAGLEHKNGEIKPKSRRRWGLISRSTKDSDDWADLDDLDFSPSLSRIDLKNKKRQSDDTLCRFESVLDLKPSEPVGTGNSAPTQTSYQRRDTPTLRSAAKQHYLKHSRYLPGISIRNGILSNPGKEFIPPNPWSSSGLSGKSSGTMSVISKVNSVGSSSTSSSGLTGNYVPSFLKKEIGSAMQRVHLAPIPDPSPGYSSLKAMRPHPGRPFFHTQPRSTPGLIPRPPAAQPVHGRTDWASKYASRR"
aligner.score(p1, p2)

#alignments = aligner.score(p1, p2)
#for alignment in sorted(alignments):
#    print("Score = %.1f:" % alignment.score)
#    print(alignment)
"""