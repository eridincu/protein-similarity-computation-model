# -*- coding: utf-8 -*-
"""CMPE 492.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_NyD2sntPLPA7g0-ltrEI1Jjj61rC5ve

# **Machine Learning for Protein Similarity Computation**
"""

import io
import json
import random
import re

# import lightgbm
import numpy as np
import pandas as pd
from Bio import Align
from transformers import AutoModel, AutoTokenizer

import logging

SW_SCORES_PATH = "sw_sim_matrix.csv"

PROTEIN_TOKENIZER = AutoTokenizer.from_pretrained('Rostlab/prot_bert', do_lower_case=False)
PROTBERT = AutoModel.from_pretrained('Rostlab/prot_bert')

def print_data(data):
  for index, value in data.items():
    print(f"Index : {index}, Value : {value}")


def get_protein_sequences_json(file_path):
  '''
  
  Returns:
    Proteins object storing <str, str>:
      - Key: name
      - Value: sequence
  '''
  p_file = open(file_path)
  proteins = json.load(p_file)

  logging.info("Reading protein sequences COMPLETE.")
  for name, sequence in proteins.items():
    logging.debug(f'Name:{name}')
    logging.debug(f'Sequence:{sequence}')

  return proteins


def get_similarity_matrix(filename):
  df =  pd.read_csv(filename)
  logging.info('Similarity matrix is obtained.')

  return df


def get_protbert_embedding(aa_sequence: str):
  cleaned_sequence = re.sub(r'[UZOB]', 'X', aa_sequence)
  tokens = PROTEIN_TOKENIZER(cleaned_sequence, return_tensors='pt')
  output = PROTBERT(**tokens)
  return output.last_hidden_state.detach().numpy().mean(axis=1)


def prepare_similarity_scores(similarity_matrix):
  similarity_score_dict = {}

  for _, score_list in similarity_matrix.iterrows():
    c = 0
    for score in score_list[1:]:
      c += 1
      similarity_score_dict[(score_list[0], similarity_matrix.columns[c])] = score

    return similarity_score_dict


def prepare_model_data(similarity_matrix: pd.DataFrame):
  plain_data = list(prepare_similarity_scores(similarity_matrix).items())
  random.shuffle(plain_data)

  train_data = plain_data[0:400]
  test_data = plain_data[400:]

  return train_data, test_data

similarity_matrix = get_similarity_matrix('sw_sim_matrix.csv')
protein_sequences = get_protein_sequences_json('proteins.json')

train_data, test_data = prepare_model_data(similarity_matrix)

x = get_protbert_embedding("MDRMKKIKRQLSMTLRGGRGIDKTNGAPEQIGLDESGGGGGSDPGEAPTRAAPGELRSARGPLSSAPEIVHEDLKMGSDGESDQASATSSDEVQSPVRVRMRNHPPRKISTEDINKRLSLPADIRLPEGYLEKLTLNSPIFDKPLSRRLRRVSLSEIGFGKLETYIKLDKLGEGTYATVYKGKSKLTDNLVALKEIRLEHEEGAPCTAIREVSLLKDLKHANIVTLHDIIHTEKSLTLVFEYLDKDLKQYLDDCGNIINMHNVKLFLFQLLRGLAYCHRQKVLHRDLKPQNLLINERGELKLADFGLARAKSIPTKTYSNEVVTLWYRPPDILLGSTDYSTQIDMWGVGCIFYEMATGRPLFPGSTVEEQLHFIFRILGTPTEETWPGILSNEEFKTYNYPKYRAEALLSHAPRLDSDGADLLTKLLQFEGRNRISAEDAMKHPFFLSLGERIHKLPDTTSIFALKEIQLQKEASLRSSSMPDSGRPAFRVVDTEF")
print()
"""
plain_data = list(df_data.items())
random.shuffle(plain_data)
train_X = plain_data[0:400]
test_X = plain_data[400:]
print(len(train_X))
print(len(test_X))
print_data(train_X)
print_data(test_X)

df_SW_score = pd.read_csv('sw_sim_matrix.csv')
SW_score_dict = {}
c = 0
for _, score_list in df_SW_score.iterrows():
  c = 0
  for score in score_list[1:]:
    c = c + 1
    #print(score_list[0], df_SW_score.columns[c], score)
    SW_score_dict[(score_list[0], df_SW_score.columns[c])] = score

print(SW_score_dict[("P54762", "Q12852")])
print(len(SW_score_dict.keys()))

"""### PROTBERT"""

"""
protein_tokenizer = AutoTokenizer.from_pretrained('Rostlab/prot_bert', do_lower_case=False)
protbert = AutoModel.from_pretrained('Rostlab/prot_bert')

def get_protbert_embedding(aa_sequence: str):
   cleaned_sequence = re.sub(r'[UZOB]', 'X', aa_sequence)
   tokens = protein_tokenizer(cleaned_sequence, return_tensors='pt')
   output = protbert(**tokens)
   return output.last_hidden_state.detach().numpy().mean(axis=1)

def update_plain_data(data, func):
  vector_data = {}
  prior_embedding = []
  for id, seq in data:
    vector_data[id] = get_protbert_embedding(seq)
    if not prior_embedding:
      prior_embedding = vector_data[id]

    if prior_embedding == vector_data[id]:
      print("Lists are equal.")
    else:
      print("Lists are not equal.")
    prior_embedding = vector_data[id]

  return vector_data

train_X = update_plain_data(train_X, get_protbert_embedding)
test_X = update_plain_data(test_X, get_protbert_embedding)

print(train_X["P53350"])
asd = np.concatenate((train_X["P53350"],np.flip(train_X["P53350"])), axis=1)
print(asd)
print(np.flip(asd))
print(np.shape(asd))

train_X_final = {}
train_Y_final = {}
for id, vector in train_X.items():
  for id2, vector2 in train_X.items():
    train_X_final[(id, id2)] = np.concatenate((vector, vector2), axis=1)
    train_Y_final[(id, id2)] = SW_score_dict[(id, id2)]

print_data(train_X_final)
print_data(train_Y_final)

_prot = get_protbert_embedding("MDRMKKIKRQLSMTLRGGRGIDKTNGAPEQIGLDESGGGGGSDPGEAPTRAAPGELRSARGPLSSAPEIVHEDLKMGSDGESDQASATSSDEVQSPVRVRMRNHPPRKISTEDINKRLSLPADIRLPEGYLEKLTLNSPIFDKPLSRRLRRVSLSEIGFGKLETYIKLDKLGEGTYATVYKGKSKLTDNLVALKEIRLEHEEGAPCTAIREVSLLKDLKHANIVTLHDIIHTEKSLTLVFEYLDKDLKQYLDDCGNIINMHNVKLFLFQLLRGLAYCHRQKVLHRDLKPQNLLINERGELKLADFGLARAKSIPTKTYSNEVVTLWYRPPDILLGSTDYSTQIDMWGVGCIFYEMATGRPLFPGSTVEEQLHFIFRILGTPTEETWPGILSNEEFKTYNYPKYRAEALLSHAPRLDSDGADLLTKLLQFEGRNRISAEDAMKHPFFLSLGERIHKLPDTTSIFALKEIQLQKEASLRSSSMPDSGRPAFRVVDTEF")
print(_prot)

!pip install biopython

aligner = Align.PairwiseAligner()
aligner.mode = "local"
print(aligner.algorithm)
p1 = "MSKSKCSVGLMSSVVAPAKEPNAVGPKEVELILVKEQNGVQLTSSTLTNPRQSPVEAQDRETWGKKIDFLLSVIGFAVDLANVWRFPYLCYKNGGGAFLVPYLLFMVIAGMPLFYMELALGQFNREGAAGVWKICPILKGVGFTVILISLYVGFFYNVIIAWALHYLFSSFTTELPWIHCNNSWNSPNCSDAHPGDSSGDSSGLNDTFGTTPAAEYFERGVLHLHQSHGIDDLGPPRWQLTACLVLVIVLLYFSLWKGVKTSGKVVWITATMPYVVLTALLLRGVTLPGAIDGIRAYLSVDFYRLCEASVWIDAATQVCFSLGVGFGVLIAFSSYNKFTNNCYRDAIVTTSINSLTSFSSGFVVFSFLGYMAQKHSVPIGDVAKDGPGLIFIIYPEAIATLPLSSAWAVVFFIMLLTLGIDSAMGGMESVITGLIDEFQLLHRHRELFTLFIVLATFLLSLFCVTNGGIYVFTLLDHFAAGTSILFGVLIEAIGVAWFYGVGQFSDDIQQMTGQRPSLYWRLCWKLVSPCFLLFVVVVSIVTFRPPHYGAYIFPDWANALGWVIATSSMAMVPIYAAYKFCSLPGSFREKLAYAIAPEKDRELVDRGEVRQFTLRHWLKV"
p2 = "MNRYTTIRQLGDGTYGSVLLGRSIESGELIAIKKMKRKFYSWEECMNLREVKSLKKLNHANVVKLKEVIRENDHLYFIFEYMKENLYQLIKERNKLFPESAIRNIMYQILQGLAFIHKHGFFHRDLKPENLLCMGPELVKIADFGLAREIRSKPPYTDYVSTRWYRAPEVLLRSTNYSSPIDVWAVGCIMAEVYTLRPLFPGASEIDTIFKICQVLGTPKKTDWPEGYQLSSAMNFRWPQCVPNNLKTLIPNASSEAVQLLRDMLQWDPKKRPTASQALRYPYFQVGHPLGSTTQNLQDSEKPQKGILEKAGPPPYIKPVPPAQPPAKPHTRISSRQHQASQPPLHLTYPYKAEVSRTDHPSHLQEDKPSPLLFPSLHNKHPQSKITAGLEHKNGEIKPKSRRRWGLISRSTKDSDDWADLDDLDFSPSLSRIDLKNKKRQSDDTLCRFESVLDLKPSEPVGTGNSAPTQTSYQRRDTPTLRSAAKQHYLKHSRYLPGISIRNGILSNPGKEFIPPNPWSSSGLSGKSSGTMSVISKVNSVGSSSTSSSGLTGNYVPSFLKKEIGSAMQRVHLAPIPDPSPGYSSLKAMRPHPGRPFFHTQPRSTPGLIPRPPAAQPVHGRTDWASKYASRR"
aligner.score(p1, p2)

#alignments = aligner.score(p1, p2)
#for alignment in sorted(alignments):
#    print("Score = %.1f:" % alignment.score)
#    print(alignment)
"""