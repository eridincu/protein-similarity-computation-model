# -*- coding: utf-8 -*-
"""CMPE 492.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_NyD2sntPLPA7g0-ltrEI1Jjj61rC5ve

# **Machine Learning for Protein Similarity Computation**
"""

# For getting csv file locally
from google.colab import files  
uploaded = files.upload()

import pandas as pd
import lightgbm
import numpy as np

SW_score_file = "sw_sim_matrix.csv"

import io

# sw_sim_df = pd.read_csv(io.BytesIO(uploaded['sw_sim_matrix.csv']))
print(uploaded)
# Dataset is now stored in a Pandas Dataframe

# For getting csv file from github
url = 'copied_raw_GH_link'
df1 = pd.read_csv(url)
# Dataset is now stored in a Pandas Dataframe

import io
df_data = pd.read_json(io.BytesIO(uploaded['proteins.json']), typ="series")

def print_data(data):
  count = 0
  for index, value in data.items():
    count = count + 1
    print(f"Index : {index}, Value : {value}")
    if count == 5:
      break

import random
plain_data = list(df_data.items())
random.shuffle(plain_data)
train_X = plain_data[0:400]
test_X = plain_data[400:]
print(len(train_X))
print(len(test_X))
print_data(train_X)
print_data(test_X)

df_SW_score = pd.read_csv('sw_sim_matrix.csv')
SW_score_dict = {}
c = 0
for _, score_list in df_SW_score.iterrows():
  c = 0
  for score in score_list[1:]:
    c = c + 1
    #print(score_list[0], df_SW_score.columns[c], score)
    SW_score_dict[(score_list[0], df_SW_score.columns[c])] = score

print(SW_score_dict[("P54762", "Q12852")])
print(len(SW_score_dict.keys()))

"""### PROTBERT"""

!pip install transformers
import re
import transformers
from transformers import AutoTokenizer, AutoModel

protein_tokenizer = AutoTokenizer.from_pretrained('Rostlab/prot_bert', do_lower_case=False)
protbert = AutoModel.from_pretrained('Rostlab/prot_bert')

def get_protbert_embedding(aa_sequence: str):
   cleaned_sequence = re.sub(r'[UZOB]', 'X', aa_sequence)
   tokens = protein_tokenizer(cleaned_sequence, return_tensors='pt')
   output = protbert(**tokens)
   return output.last_hidden_state.detach().numpy().mean(axis=1)

def update_plain_data(data, func):
  vector_data = {}
  prior_embedding = []
  for id, seq in data:
    vector_data[id] = get_protbert_embedding(seq)
    if not prior_embedding:
      prior_embedding = vector_data[id]

    if prior_embedding == vector_data[id]:
      print("Lists are equal.")
    else:
      print("Lists are not equal.")
    prior_embedding = vector_data[id]

  return vector_data

train_X = update_plain_data(train_X, get_protbert_embedding)
test_X = update_plain_data(test_X, get_protbert_embedding)

print(train_X["P53350"])
asd = np.concatenate((train_X["P53350"],np.flip(train_X["P53350"])), axis=1)
print(asd)
print(np.flip(asd))
print(np.shape(asd))

train_X_final = {}
train_Y_final = {}
for id, vector in train_X.items():
  for id2, vector2 in train_X.items():
    train_X_final[(id, id2)] = np.concatenate((vector, vector2), axis=1)
    train_Y_final[(id, id2)] = SW_score_dict[(id, id2)]

print_data(train_X_final)
print_data(train_Y_final)

_prot = get_protbert_embedding("MDRMKKIKRQLSMTLRGGRGIDKTNGAPEQIGLDESGGGGGSDPGEAPTRAAPGELRSARGPLSSAPEIVHEDLKMGSDGESDQASATSSDEVQSPVRVRMRNHPPRKISTEDINKRLSLPADIRLPEGYLEKLTLNSPIFDKPLSRRLRRVSLSEIGFGKLETYIKLDKLGEGTYATVYKGKSKLTDNLVALKEIRLEHEEGAPCTAIREVSLLKDLKHANIVTLHDIIHTEKSLTLVFEYLDKDLKQYLDDCGNIINMHNVKLFLFQLLRGLAYCHRQKVLHRDLKPQNLLINERGELKLADFGLARAKSIPTKTYSNEVVTLWYRPPDILLGSTDYSTQIDMWGVGCIFYEMATGRPLFPGSTVEEQLHFIFRILGTPTEETWPGILSNEEFKTYNYPKYRAEALLSHAPRLDSDGADLLTKLLQFEGRNRISAEDAMKHPFFLSLGERIHKLPDTTSIFALKEIQLQKEASLRSSSMPDSGRPAFRVVDTEF")
print(_prot)

!pip install biopython

from Bio import Align
aligner = Align.PairwiseAligner()
aligner.mode = "local"
print(aligner.algorithm)
p1 = "MSKSKCSVGLMSSVVAPAKEPNAVGPKEVELILVKEQNGVQLTSSTLTNPRQSPVEAQDRETWGKKIDFLLSVIGFAVDLANVWRFPYLCYKNGGGAFLVPYLLFMVIAGMPLFYMELALGQFNREGAAGVWKICPILKGVGFTVILISLYVGFFYNVIIAWALHYLFSSFTTELPWIHCNNSWNSPNCSDAHPGDSSGDSSGLNDTFGTTPAAEYFERGVLHLHQSHGIDDLGPPRWQLTACLVLVIVLLYFSLWKGVKTSGKVVWITATMPYVVLTALLLRGVTLPGAIDGIRAYLSVDFYRLCEASVWIDAATQVCFSLGVGFGVLIAFSSYNKFTNNCYRDAIVTTSINSLTSFSSGFVVFSFLGYMAQKHSVPIGDVAKDGPGLIFIIYPEAIATLPLSSAWAVVFFIMLLTLGIDSAMGGMESVITGLIDEFQLLHRHRELFTLFIVLATFLLSLFCVTNGGIYVFTLLDHFAAGTSILFGVLIEAIGVAWFYGVGQFSDDIQQMTGQRPSLYWRLCWKLVSPCFLLFVVVVSIVTFRPPHYGAYIFPDWANALGWVIATSSMAMVPIYAAYKFCSLPGSFREKLAYAIAPEKDRELVDRGEVRQFTLRHWLKV"
p2 = "MNRYTTIRQLGDGTYGSVLLGRSIESGELIAIKKMKRKFYSWEECMNLREVKSLKKLNHANVVKLKEVIRENDHLYFIFEYMKENLYQLIKERNKLFPESAIRNIMYQILQGLAFIHKHGFFHRDLKPENLLCMGPELVKIADFGLAREIRSKPPYTDYVSTRWYRAPEVLLRSTNYSSPIDVWAVGCIMAEVYTLRPLFPGASEIDTIFKICQVLGTPKKTDWPEGYQLSSAMNFRWPQCVPNNLKTLIPNASSEAVQLLRDMLQWDPKKRPTASQALRYPYFQVGHPLGSTTQNLQDSEKPQKGILEKAGPPPYIKPVPPAQPPAKPHTRISSRQHQASQPPLHLTYPYKAEVSRTDHPSHLQEDKPSPLLFPSLHNKHPQSKITAGLEHKNGEIKPKSRRRWGLISRSTKDSDDWADLDDLDFSPSLSRIDLKNKKRQSDDTLCRFESVLDLKPSEPVGTGNSAPTQTSYQRRDTPTLRSAAKQHYLKHSRYLPGISIRNGILSNPGKEFIPPNPWSSSGLSGKSSGTMSVISKVNSVGSSSTSSSGLTGNYVPSFLKKEIGSAMQRVHLAPIPDPSPGYSSLKAMRPHPGRPFFHTQPRSTPGLIPRPPAAQPVHGRTDWASKYASRR"
aligner.score(p1, p2)

#alignments = aligner.score(p1, p2)
#for alignment in sorted(alignments):
#    print("Score = %.1f:" % alignment.score)
#    print(alignment)